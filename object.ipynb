{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import io\n","import collections\n","import pandas as pd\n","import numpy as np\n","import functools\n","import matplotlib.pyplot as plt\n","import cv2\n","import json\n","\n","from sklearn import preprocessing\n","\n","import xml.etree.ElementTree as ET\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import SequentialSampler\n","\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import os\n","from albumentations import RandomRotate90\n","from tensorflow.keras import mixed_precision\n","import gc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:49.121682Z","iopub.status.busy":"2023-11-09T01:04:49.121013Z","iopub.status.idle":"2023-11-09T01:04:49.125148Z","shell.execute_reply":"2023-11-09T01:04:49.124457Z","shell.execute_reply.started":"2023-11-09T01:04:49.121652Z"},"trusted":true},"outputs":[],"source":["# # # data paths\n","train_csv_path = 'dataset/final_train_labels.csv'\n","test_csv_path = 'dataset/final_test_labels.csv'\n","val_csv_path = 'dataset/final_validate_labels.csv'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:50.101162Z","iopub.status.busy":"2023-11-09T01:04:50.100603Z","iopub.status.idle":"2023-11-09T01:04:50.423021Z","shell.execute_reply":"2023-11-09T01:04:50.422256Z","shell.execute_reply.started":"2023-11-09T01:04:50.101134Z"},"trusted":true},"outputs":[],"source":["# read, train, test and validation dataset\n","train_data = pd.read_csv(train_csv_path)\n","test_data = pd.read_csv(test_csv_path)\n","val_data = pd.read_csv(val_csv_path) "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:51.325131Z","iopub.status.busy":"2023-11-09T01:04:51.324527Z","iopub.status.idle":"2023-11-09T01:04:51.332135Z","shell.execute_reply":"2023-11-09T01:04:51.331387Z","shell.execute_reply.started":"2023-11-09T01:04:51.325086Z"},"trusted":true},"outputs":[],"source":["# do not run this if youre creating the csv for tensorflow object detection\n","\n","train_data['integer_label'] = train_data['integer_label'] - 1\n","test_data['integer_label'] = test_data['integer_label'] - 1\n","val_data['integer_label'] = val_data['integer_label'] - 1"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:52.350828Z","iopub.status.busy":"2023-11-09T01:04:52.349896Z","iopub.status.idle":"2023-11-09T01:04:52.358907Z","shell.execute_reply":"2023-11-09T01:04:52.358089Z","shell.execute_reply.started":"2023-11-09T01:04:52.350797Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(40852, 12)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Get the initial shape of the DataFrame\n","initial_shape = train_data.shape\n","initial_shape"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:53.567156Z","iopub.status.busy":"2023-11-09T01:04:53.566378Z","iopub.status.idle":"2023-11-09T01:04:53.589629Z","shell.execute_reply":"2023-11-09T01:04:53.588693Z","shell.execute_reply.started":"2023-11-09T01:04:53.567115Z"},"trusted":true},"outputs":[],"source":["# Filter rows where x1 is not greater than or equal to x2\n","train_data = train_data[train_data['x1'] < train_data['x2']]\n","# Filter rows where y1 is not greater than or equal to y2\n","train_data = train_data[train_data['y1'] < train_data['y2']]\n","\n","# Filter rows where x1 is not greater than or equal to x2\n","test_data = test_data[test_data['x1'] < test_data['x2']]\n","# Filter rows where y1 is not greater than or equal to y2\n","test_data = test_data[test_data['y1'] < test_data['y2']]\n","\n","# Filter rows where x1 is not greater than or equal to x2\n","val_data = val_data[val_data['x1'] < val_data['x2']]\n","# Filter rows where y1 is not greater than or equal to y2\n","val_data = val_data[val_data['y1'] < val_data['y2']]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:54.505150Z","iopub.status.busy":"2023-11-09T01:04:54.504825Z","iopub.status.idle":"2023-11-09T01:04:54.510642Z","shell.execute_reply":"2023-11-09T01:04:54.509825Z","shell.execute_reply.started":"2023-11-09T01:04:54.505125Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(40850, 12)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Get the final shape of the DataFrame\n","final_shape = train_data.shape\n","final_shape"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:55.355387Z","iopub.status.busy":"2023-11-09T01:04:55.355116Z","iopub.status.idle":"2023-11-09T01:04:55.372364Z","shell.execute_reply":"2023-11-09T01:04:55.371689Z","shell.execute_reply.started":"2023-11-09T01:04:55.355365Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>crop</th>\n","      <th>class</th>\n","      <th>fname</th>\n","      <th>img_path</th>\n","      <th>x1</th>\n","      <th>y1</th>\n","      <th>x2</th>\n","      <th>y2</th>\n","      <th>id</th>\n","      <th>integer_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Tomato</td>\n","      <td>Tomato Late Blight</td>\n","      <td>e701b2d9-d9ef-49dd-a9b2-067ac10dff12.jpg</td>\n","      <td>dataset/train\\e701b2d9-d9ef-49dd-a9b2-067ac10d...</td>\n","      <td>191.42496</td>\n","      <td>306.85420</td>\n","      <td>256.16083</td>\n","      <td>391.27650</td>\n","      <td>0</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Corn</td>\n","      <td>Corn Healthy</td>\n","      <td>ee11488a-d7c4-4426-898b-0153fe55d82b.jpg</td>\n","      <td>dataset/train\\ee11488a-d7c4-4426-898b-0153fe55...</td>\n","      <td>370.76172</td>\n","      <td>459.11493</td>\n","      <td>457.52620</td>\n","      <td>595.26400</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Corn</td>\n","      <td>Corn Common Rust</td>\n","      <td>8c38b101-19ed-4353-b518-63e1128fc5b7.jpg</td>\n","      <td>dataset/train\\8c38b101-19ed-4353-b518-63e1128f...</td>\n","      <td>167.16748</td>\n","      <td>134.74731</td>\n","      <td>214.36250</td>\n","      <td>330.76570</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Corn</td>\n","      <td>Corn Streak</td>\n","      <td>627ce1e3-0354-4713-9f12-3d2db183e3e0.jpg</td>\n","      <td>dataset/train\\627ce1e3-0354-4713-9f12-3d2db183...</td>\n","      <td>517.21704</td>\n","      <td>73.61801</td>\n","      <td>535.50210</td>\n","      <td>302.75104</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Pepper</td>\n","      <td>Pepper Leaf Curl</td>\n","      <td>fe203180-5056-479c-abe4-e9d4c613dc01.jpg</td>\n","      <td>dataset/train\\fe203180-5056-479c-abe4-e9d4c613...</td>\n","      <td>149.65358</td>\n","      <td>178.65503</td>\n","      <td>225.32716</td>\n","      <td>296.88910</td>\n","      <td>4</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   width  height    crop               class  \\\n","0    640     640  Tomato  Tomato Late Blight   \n","1    640     640    Corn        Corn Healthy   \n","2    640     640    Corn    Corn Common Rust   \n","3    640     640    Corn         Corn Streak   \n","4    640     640  Pepper    Pepper Leaf Curl   \n","\n","                                      fname  \\\n","0  e701b2d9-d9ef-49dd-a9b2-067ac10dff12.jpg   \n","1  ee11488a-d7c4-4426-898b-0153fe55d82b.jpg   \n","2  8c38b101-19ed-4353-b518-63e1128fc5b7.jpg   \n","3  627ce1e3-0354-4713-9f12-3d2db183e3e0.jpg   \n","4  fe203180-5056-479c-abe4-e9d4c613dc01.jpg   \n","\n","                                            img_path         x1         y1  \\\n","0  dataset/train\\e701b2d9-d9ef-49dd-a9b2-067ac10d...  191.42496  306.85420   \n","1  dataset/train\\ee11488a-d7c4-4426-898b-0153fe55...  370.76172  459.11493   \n","2  dataset/train\\8c38b101-19ed-4353-b518-63e1128f...  167.16748  134.74731   \n","3  dataset/train\\627ce1e3-0354-4713-9f12-3d2db183...  517.21704   73.61801   \n","4  dataset/train\\fe203180-5056-479c-abe4-e9d4c613...  149.65358  178.65503   \n","\n","          x2         y2  id  integer_label  \n","0  256.16083  391.27650   0             16  \n","1  457.52620  595.26400   1              3  \n","2  214.36250  330.76570   2              2  \n","3  535.50210  302.75104   3              4  \n","4  225.32716  296.88910   4              6  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:56.087196Z","iopub.status.busy":"2023-11-09T01:04:56.086898Z","iopub.status.idle":"2023-11-09T01:04:56.382747Z","shell.execute_reply":"2023-11-09T01:04:56.382024Z","shell.execute_reply.started":"2023-11-09T01:04:56.087172Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>crop</th>\n","      <th>class</th>\n","      <th>fname</th>\n","      <th>img_path</th>\n","      <th>x1</th>\n","      <th>y1</th>\n","      <th>x2</th>\n","      <th>y2</th>\n","      <th>id</th>\n","      <th>integer_label</th>\n","      <th>img_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Tomato</td>\n","      <td>Tomato Late Blight</td>\n","      <td>e701b2d9-d9ef-49dd-a9b2-067ac10dff12.jpg</td>\n","      <td>dataset/train\\e701b2d9-d9ef-49dd-a9b2-067ac10d...</td>\n","      <td>191.42496</td>\n","      <td>306.85420</td>\n","      <td>256.16083</td>\n","      <td>391.27650</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>e701b2d9-d9ef-49dd-a9b2-067ac10dff12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Corn</td>\n","      <td>Corn Healthy</td>\n","      <td>ee11488a-d7c4-4426-898b-0153fe55d82b.jpg</td>\n","      <td>dataset/train\\ee11488a-d7c4-4426-898b-0153fe55...</td>\n","      <td>370.76172</td>\n","      <td>459.11493</td>\n","      <td>457.52620</td>\n","      <td>595.26400</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>ee11488a-d7c4-4426-898b-0153fe55d82b</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Corn</td>\n","      <td>Corn Common Rust</td>\n","      <td>8c38b101-19ed-4353-b518-63e1128fc5b7.jpg</td>\n","      <td>dataset/train\\8c38b101-19ed-4353-b518-63e1128f...</td>\n","      <td>167.16748</td>\n","      <td>134.74731</td>\n","      <td>214.36250</td>\n","      <td>330.76570</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>8c38b101-19ed-4353-b518-63e1128fc5b7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Corn</td>\n","      <td>Corn Streak</td>\n","      <td>627ce1e3-0354-4713-9f12-3d2db183e3e0.jpg</td>\n","      <td>dataset/train\\627ce1e3-0354-4713-9f12-3d2db183...</td>\n","      <td>517.21704</td>\n","      <td>73.61801</td>\n","      <td>535.50210</td>\n","      <td>302.75104</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>627ce1e3-0354-4713-9f12-3d2db183e3e0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>640</td>\n","      <td>640</td>\n","      <td>Pepper</td>\n","      <td>Pepper Leaf Curl</td>\n","      <td>fe203180-5056-479c-abe4-e9d4c613dc01.jpg</td>\n","      <td>dataset/train\\fe203180-5056-479c-abe4-e9d4c613...</td>\n","      <td>149.65358</td>\n","      <td>178.65503</td>\n","      <td>225.32716</td>\n","      <td>296.88910</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>fe203180-5056-479c-abe4-e9d4c613dc01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   width  height    crop               class  \\\n","0    640     640  Tomato  Tomato Late Blight   \n","1    640     640    Corn        Corn Healthy   \n","2    640     640    Corn    Corn Common Rust   \n","3    640     640    Corn         Corn Streak   \n","4    640     640  Pepper    Pepper Leaf Curl   \n","\n","                                      fname  \\\n","0  e701b2d9-d9ef-49dd-a9b2-067ac10dff12.jpg   \n","1  ee11488a-d7c4-4426-898b-0153fe55d82b.jpg   \n","2  8c38b101-19ed-4353-b518-63e1128fc5b7.jpg   \n","3  627ce1e3-0354-4713-9f12-3d2db183e3e0.jpg   \n","4  fe203180-5056-479c-abe4-e9d4c613dc01.jpg   \n","\n","                                            img_path         x1         y1  \\\n","0  dataset/train\\e701b2d9-d9ef-49dd-a9b2-067ac10d...  191.42496  306.85420   \n","1  dataset/train\\ee11488a-d7c4-4426-898b-0153fe55...  370.76172  459.11493   \n","2  dataset/train\\8c38b101-19ed-4353-b518-63e1128f...  167.16748  134.74731   \n","3  dataset/train\\627ce1e3-0354-4713-9f12-3d2db183...  517.21704   73.61801   \n","4  dataset/train\\fe203180-5056-479c-abe4-e9d4c613...  149.65358  178.65503   \n","\n","          x2         y2  id  integer_label  \\\n","0  256.16083  391.27650   0             16   \n","1  457.52620  595.26400   1              3   \n","2  214.36250  330.76570   2              2   \n","3  535.50210  302.75104   3              4   \n","4  225.32716  296.88910   4              6   \n","\n","                                 img_id  \n","0  e701b2d9-d9ef-49dd-a9b2-067ac10dff12  \n","1  ee11488a-d7c4-4426-898b-0153fe55d82b  \n","2  8c38b101-19ed-4353-b518-63e1128fc5b7  \n","3  627ce1e3-0354-4713-9f12-3d2db183e3e0  \n","4  fe203180-5056-479c-abe4-e9d4c613dc01  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# remove .jpg extension from image_id \n","train_data['img_id'] = train_data['fname'].apply(lambda x:x.split('.')).map(lambda x:x[0])\n","test_data['img_id'] = test_data['fname'].apply(lambda x:x.split('.')).map(lambda x:x[0])\n","val_data['img_id'] = val_data['fname'].apply(lambda x:x.split('.')).map(lambda x:x[0])\n","# df.drop(columns=['image_id'], inplace=True)\n","train_data.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:58.109384Z","iopub.status.busy":"2023-11-09T01:04:58.108432Z","iopub.status.idle":"2023-11-09T01:04:58.123597Z","shell.execute_reply":"2023-11-09T01:04:58.122766Z","shell.execute_reply.started":"2023-11-09T01:04:58.109347Z"},"trusted":true},"outputs":[{"data":{"text/plain":["class                      integer_label\n","Corn Cercospora Leaf Spot  1                6532\n","Tomato Septoria            19               6500\n","Tomato Late Blight         16               3832\n","Corn Streak                4                3205\n","Tomato Healthy             22               2839\n","Pepper Septoria            13               2254\n","Pepper Leaf Mosaic         10               2133\n","Pepper Bacterial Spot      9                1907\n","Tomato Early Blight        17               1827\n","Corn Common Rust           2                1747\n","Corn Healthy               3                1591\n","Pepper Leaf Curl           6                1525\n","Tomato Fusarium            20                863\n","Pepper Healthy             11                710\n","Pepper Late Blight         14                558\n","Pepper Leaf Blight         8                 516\n","Pepper Fusarium            12                490\n","Pepper Cercospora          7                 489\n","Tomato Bacterial Spot      18                450\n","Tomato Leaf Curl           21                450\n","Tomato Mosaic              23                170\n","Corn Northern Leaf Blight  5                 159\n","Pepper Early Blight        15                103\n","dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["classes_ = train_data[['class','integer_label']].value_counts()\n","classes_"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:04:59.295032Z","iopub.status.busy":"2023-11-09T01:04:59.294390Z","iopub.status.idle":"2023-11-09T01:04:59.303019Z","shell.execute_reply":"2023-11-09T01:04:59.302178Z","shell.execute_reply.started":"2023-11-09T01:04:59.294996Z"},"trusted":true},"outputs":[{"data":{"text/plain":["23"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_data['class'].nunique()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:00.260392Z","iopub.status.busy":"2023-11-09T01:05:00.260056Z","iopub.status.idle":"2023-11-09T01:05:00.267092Z","shell.execute_reply":"2023-11-09T01:05:00.266414Z","shell.execute_reply.started":"2023-11-09T01:05:00.260367Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['Tomato Late Blight', 'Corn Healthy', 'Corn Common Rust',\n","       'Corn Streak', 'Pepper Leaf Curl', 'Tomato Septoria',\n","       'Pepper Bacterial Spot', 'Tomato Early Blight',\n","       'Corn Cercospora Leaf Spot', 'Tomato Healthy', 'Pepper Septoria',\n","       'Pepper Leaf Mosaic', 'Tomato Mosaic', 'Tomato Fusarium',\n","       'Tomato Bacterial Spot', 'Pepper Late Blight',\n","       'Corn Northern Leaf Blight', 'Pepper Healthy',\n","       'Pepper Early Blight', 'Pepper Fusarium', 'Pepper Leaf Blight',\n","       'Tomato Leaf Curl', 'Pepper Cercospora'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_data['class'].unique()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:01.018196Z","iopub.status.busy":"2023-11-09T01:05:01.017818Z","iopub.status.idle":"2023-11-09T01:05:01.022809Z","shell.execute_reply":"2023-11-09T01:05:01.022085Z","shell.execute_reply.started":"2023-11-09T01:05:01.018165Z"},"trusted":true},"outputs":[],"source":["def get_train_file_path(image_id):\n","    return \"dataset/train/{}.jpg\".format(image_id)\n","\n","def get_validate_file_path(image_id):\n","    return \"dataset/validate/{}.jpg\".format(image_id)\n","\n","def get_test_file_path(image_id):\n","    return \"dataset/test/{}.jpg\".format(image_id)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:02.073944Z","iopub.status.busy":"2023-11-09T01:05:02.073620Z","iopub.status.idle":"2023-11-09T01:05:02.091507Z","shell.execute_reply":"2023-11-09T01:05:02.090812Z","shell.execute_reply.started":"2023-11-09T01:05:02.073907Z"},"trusted":true},"outputs":[],"source":["def class_text_to_int(row_label, label_map):\n","    return label_map[row_label]\n","\n","label_map_path = 'dataset/label_map.json'\n","with open(label_map_path, 'r') as json_file:\n","    label_map = json.load(json_file)\n","\n","# label_map"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:03.119622Z","iopub.status.busy":"2023-11-09T01:05:03.119290Z","iopub.status.idle":"2023-11-09T01:05:03.127347Z","shell.execute_reply":"2023-11-09T01:05:03.126631Z","shell.execute_reply.started":"2023-11-09T01:05:03.119599Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{0: 'Corn Cercospora Leaf Spot',\n"," 1: 'Corn Common Rust',\n"," 2: 'Corn Healthy',\n"," 3: 'Corn Streak',\n"," 4: 'Corn Northern Leaf Blight',\n"," 5: 'Pepper Leaf Curl',\n"," 6: 'Pepper Cercospora',\n"," 7: 'Pepper Leaf Blight',\n"," 8: 'Pepper Bacterial Spot',\n"," 9: 'Pepper Leaf Mosaic',\n"," 10: 'Pepper Healthy',\n"," 11: 'Pepper Fusarium',\n"," 12: 'Pepper Septoria',\n"," 13: 'Pepper Late Blight',\n"," 14: 'Pepper Early Blight',\n"," 15: 'Tomato Late Blight',\n"," 16: 'Tomato Early Blight',\n"," 17: 'Tomato Bacterial Spot',\n"," 18: 'Tomato Septoria',\n"," 19: 'Tomato Fusarium',\n"," 20: 'Tomato Leaf Curl',\n"," 21: 'Tomato Healthy',\n"," 22: 'Tomato Mosaic'}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# make dictionary for class objects so we can call objects by their keys.\n","classes= {\n","    0: 'Corn Cercospora Leaf Spot',\n","    1: 'Corn Common Rust',\n","    2: 'Corn Healthy',\n","    3: 'Corn Streak',\n","    4: 'Corn Northern Leaf Blight',\n","    5: 'Pepper Leaf Curl',\n","    6: 'Pepper Cercospora',\n","    7: 'Pepper Leaf Blight',\n","    8: 'Pepper Bacterial Spot',\n","    9: 'Pepper Leaf Mosaic',\n","    10: 'Pepper Healthy',\n","    11: 'Pepper Fusarium',\n","    12: 'Pepper Septoria',\n","    13: 'Pepper Late Blight',\n","    14: 'Pepper Early Blight',\n","    15: 'Tomato Late Blight',\n","    16: 'Tomato Early Blight',\n","    17: 'Tomato Bacterial Spot',\n","    18: 'Tomato Septoria',\n","    19: 'Tomato Fusarium',\n","    20: 'Tomato Leaf Curl',\n","    21: 'Tomato Healthy',\n","    22: 'Tomato Mosaic'\n","}\n","classes"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:04.098070Z","iopub.status.busy":"2023-11-09T01:05:04.097658Z","iopub.status.idle":"2023-11-09T01:05:04.113070Z","shell.execute_reply":"2023-11-09T01:05:04.112211Z","shell.execute_reply.started":"2023-11-09T01:05:04.098037Z"},"trusted":true},"outputs":[{"data":{"text/plain":["40850"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data['img_id'].unique())"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:05.039351Z","iopub.status.busy":"2023-11-09T01:05:05.038608Z","iopub.status.idle":"2023-11-09T01:05:05.046201Z","shell.execute_reply":"2023-11-09T01:05:05.045488Z","shell.execute_reply.started":"2023-11-09T01:05:05.039315Z"},"trusted":true},"outputs":[],"source":["def func(image):\n","    Trgb2lms =np.array( [\n","        np.array([17.8824, 43.5161, 4.1194]),\n","        np.array([3.4557,27.1154, 3.8671]),\n","        np.array([0.0300, 0.1843, 1.4671]) \n","    ])\n","    \n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    x,y,z = image.shape\n","#     print(image.shape)\n","    cvd_due = np.array([\n","        np.array([1 ,0, 0]),   \n","        np.array([0.494207, 0, 1.24827]),   \n","        np.array([0, 0, 1]),   \n","    ])\n","    INV_Trgb2lms = np.linalg.inv(Trgb2lms) \n","\n","#     print(image.transpose(2, 0, 1).shape)\n","    out = np.dot(INV_Trgb2lms, cvd_due)\n","    out = np.dot(out, Trgb2lms)\n","    out = np.dot(out, image.transpose(2, 0, 1).reshape(3,-1)) \n","    out = out.reshape(3,x,y).transpose(1, 2, 0)\n","    out = cv2.cvtColor(np.float32(out), cv2.COLOR_RGB2BGR)\n","\n","    return out"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T01:05:53.709132Z","iopub.status.busy":"2023-11-09T01:05:53.708698Z","iopub.status.idle":"2023-11-09T01:05:53.713842Z","shell.execute_reply":"2023-11-09T01:05:53.712975Z","shell.execute_reply.started":"2023-11-09T01:05:53.709077Z"},"trusted":true},"outputs":[],"source":["# !pip install -U -q tensorflow-object-detection"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T00:59:08.219384Z","iopub.status.busy":"2023-11-09T00:59:08.218966Z","iopub.status.idle":"2023-11-09T00:59:09.310654Z","shell.execute_reply":"2023-11-09T00:59:09.309142Z","shell.execute_reply.started":"2023-11-09T00:59:08.219350Z"},"trusted":true},"outputs":[],"source":["# # tf record dataset\n","# from PIL import Image\n","# from object_detection.utils import dataset_util, label_map_util\n","# from collections import namedtuple\n","\n","# def split(df, group):\n","#     data = namedtuple('data', ['filename', 'object'])\n","#     gb = df.groupby(group)\n","#     return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","\n","# def create_tf_example(group, path):\n","#     with tf.io.gfile.GFile(os.path.join(path, '{}.jpg'.format(group.filename)), 'rb') as fid:\n","#         encoded_jpg = fid.read()\n","#     encoded_jpg_io = io.BytesIO(encoded_jpg)\n","#     image = Image.open(encoded_jpg_io)\n","#     width, height = image.size\n","\n","#     filename = group.filename.encode('utf8')\n","#     image_format = b'jpg'\n","#     xmins = []\n","#     xmaxs = []\n","#     ymins = []\n","#     ymaxs = []\n","#     classes_text = []\n","#     classes = []\n","\n","#     for _, row in group.object.iterrows():\n","#         xmins.append(row['x1'])\n","#         xmaxs.append(row['x2'])\n","#         ymins.append(row['y1'])\n","#         ymaxs.append(row['y2'])\n","#         classes_text.append(row['class'].encode('utf8'))\n","#         classes.append(row['integer_label'])\n","\n","#     tf_example = tf.train.Example(features=tf.train.Features(feature={\n","#         'image/height': dataset_util.int64_feature(height),\n","#         'image/width': dataset_util.int64_feature(width),\n","#         'image/filename': dataset_util.bytes_feature(filename),\n","#         'image/source_id': dataset_util.bytes_feature(filename),\n","#         'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","#         'image/format': dataset_util.bytes_feature(image_format),\n","#         'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","#         'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","#         'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","#         'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","#         'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","#         'image/object/class/label': dataset_util.int64_list_feature(classes),\n","#     }))\n","#     return tf_example\n","\n","# test_tfrecord_filename = 'data/test.tfrecord'\n","# validate_tfrecord_filename = 'data/validate.tfrecord'\n","# train_tfrecord_filename = 'data/train.tfrecord'"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully created the TFRecord file: data/test.tfrecord\n"]}],"source":["# writer = tf.io.TFRecordWriter(test_tfrecord_filename)\n","# path = 'dataset/test'\n","# grouped = split(test_data, 'img_id')\n","# for group in grouped:\n","#     tf_example = create_tf_example(group, path)\n","#     writer.write(tf_example.SerializeToString())\n","# writer.close()\n","# print('Successfully created the TFRecord file: {}'.format(test_tfrecord_filename))"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully created the TFRecord file: data/validate.tfrecord\n"]}],"source":["# writer = tf.io.TFRecordWriter(validate_tfrecord_filename)\n","# path = 'dataset/validate'\n","# grouped = split(val_data, 'img_id')\n","# for group in grouped:\n","#     tf_example = create_tf_example(group, path)\n","#     writer.write(tf_example.SerializeToString())\n","# writer.close()\n","# print('Successfully created the TFRecord file: {}'.format(validate_tfrecord_filename))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully created the TFRecord file: data/train.tfrecord\n"]}],"source":["# writer = tf.io.TFRecordWriter(train_tfrecord_filename)\n","# path = 'dataset/train'\n","# grouped = split(train_data, 'img_id')\n","# for group in grouped:\n","#     tf_example = create_tf_example(group, path)\n","#     writer.write(tf_example.SerializeToString())\n","# writer.close()\n","# print('Successfully created the TFRecord file: {}'.format(train_tfrecord_filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class VOCDataset(Dataset):\n","    \n","    def __init__(self, dataframe, image_dir, transforms=None):\n","        super().__init__()\n","        \n","        self.image_ids = dataframe['img_id'].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","    \n","    def __getitem__(self, index: int):\n","        image_id = self.image_ids[index]\n","        records = self.df[self.df['img_id'] == image_id]\n","        \n","        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n","        image = func(image)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","        rows, cols = image.shape[:2]\n","        \n","        boxes = records[['x1', 'y1', 'x2', 'y2']].values\n","        \n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        area = torch.as_tensor(area, dtype=torch.float32)\n","        \n","        label = records['integer_label'].values\n","        labels = torch.as_tensor(label, dtype=torch.int64)\n","        \n","        # suppose all instances are not crowd\n","        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","        \n","        target = {}\n","        target['boxes'] = boxes\n","        target['labels'] = labels\n","        # target['masks'] = None\n","        # target['image_id'] = torch.tensor([index])\n","        target['image_id'] = int(index)\n","        target['area'] = area\n","        target['iscrowd'] = iscrowd\n","        \n","        if self.transforms:\n","            sample = {\n","                'image': image,\n","                'bboxes': target['boxes'],\n","                'labels': labels\n","            }\n","            sample = self.transforms(**sample)\n","            image = sample['image']\n","            \n","            # Find and correct invalid bounding boxes\n","            for i in range(len(sample['bboxes'])):\n","                x1, y1, x2, y2 = sample['bboxes'][i]\n","                if x1 >= x2:\n","                    x1, x2 = x2 - 1, x1 + 1\n","                if y1 >= y2:\n","                    y1, y2 = y2 - 1, y1 + 1\n","                sample['bboxes'][i] = [x1, y1, x2, y2]\n","\n","            \n","            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n","            \n","            return image, target\n","        \n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_transform_train():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n","\n","def get_transform_valid():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VOCDataset(train_data, 'dataset/train' , get_transform_train())\n","valid_dataset = VOCDataset(val_data, 'dataset/validate', get_transform_valid())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# split the dataset in train and test set\n","# indices = torch.randperm(len(train_dataset)).tolist()\n","\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size=4,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["images, targets= next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v for k, v in t.items()} for t in targets] #v.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","for i, (image, target) in enumerate(zip(images, targets)):\n","    plt.subplot(2,2, i+1)\n","    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n","    sample = images[i].permute(1,2,0).cpu().numpy()\n","    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(\n","            sample,\n","            (box[0], box[1]),\n","            (box[2], box[3]),\n","            (0, 0, 220), 2\n","        )\n","        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n","\n","    plt.axis('off')\n","    plt.imshow(sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT) # pretrained=True  # weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_classes = 23\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone https://github.com/pytorch/vision.git\n","!cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from engine import train_one_epoch, evaluate\n","import utils"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","# let's train it for 2 epochs\n","num_epochs = 4\n","\n","for epoch in range(num_epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset\n","    evaluate(model, valid_data_loader, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os \n","import subprocess\n","from IPython.display import FileLink\n","os.makedirs('output')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### For kaggle use only\n","# def download_file(path, download_file_name):\n","#     \"\"\"\n","#         download file/folder from the working directory\n","#     \"\"\"\n","#     os.chdir('/kaggle/working/')\n","#     zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n","#     command = f\"zip {zip_name} {path} -r\"\n","#     result = subprocess.run(command, shell=True, capture_output=True, text=True)\n","#     if result.returncode != 0:\n","#         print(\"Unable to run zip command!\")\n","#         print(result.stderr)\n","#         return\n","#     display(FileLink(f'{download_file_name}.zip'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'output/faster_rcnn_state.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model, 'output/faster_not_jit_rcnn_state.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_scripted = torch.jit.script(model) # Export to TorchScript\n","model_scripted.save('output/faster_rcnn_jit_state.pt') # Save"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### for kaggle use only\n","# download_file('output', 'output')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# load  a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None, weights_backbone=None)  # (pretrained=False, pretrained_backbone=False)\n","\n","WEIGHTS_FILE = \"output/faster_rcnn_state.pth\"\n","\n","num_classes = 23\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the traines weights\n","model.load_state_dict(torch.load(WEIGHTS_FILE))\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def obj_detector(img):\n","    img = cv2.imread(img, cv2.IMREAD_COLOR)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","\n","\n","    img /= 255.0\n","    img = torch.from_numpy(img)\n","    img = img.unsqueeze(0)\n","    img = img.permute(0,3,1,2)\n","    \n","    model.eval()\n","\n","#     detection_threshold = 0.70\n","    \n","    img = list(im.to(device) for im in img)\n","    output = model(img)\n","\n","    for i , im in enumerate(img):\n","        boxes = output[i]['boxes'].data.cpu().numpy()\n","        scores = output[i]['scores'].data.cpu().numpy()\n","        labels = output[i]['labels'].data.cpu().numpy()\n","\n","#         labels = labels[scores >= detection_threshold]\n","#         boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","#         scores = scores[scores >= detection_threshold]\n","\n","#         boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n","#         boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n","    \n","    sample = img[0].permute(1,2,0).cpu().numpy()\n","    sample = np.array(sample)\n","    boxes = output[0]['boxes'].data.cpu().numpy()\n","    name = output[0]['labels'].data.cpu().numpy()\n","    scores = output[0]['scores'].data.cpu().numpy()\n","    boxes = boxes.astype(np.int32)\n","    names = name.tolist()\n","    \n","    return names, boxes, sample"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pred_path = \"dataset/test\"\n","pred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,60))\n","for i, images in enumerate(pred_files):\n","    if i > 10:break\n","    plt.subplot(10,2,i+1)\n","    names,boxes,sample = obj_detector(images)\n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(\n","            sample,\n","            (box[0], box[1]),\n","            (box[2], box[3]),\n","            (0, 220, 0), 2\n","        )\n","        cv2.putText(sample, classes[names[i]], (box[0],box[1]-5),cv2.FONT_HERSHEY_COMPLEX ,0.7,(220,0,0),1,cv2.LINE_AA)  \n","\n","    plt.axis('off')\n","    plt.imshow(sample)\n","#     plt.savefig('save_image.png', bbox_inches='tight')  # if you want to save result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
